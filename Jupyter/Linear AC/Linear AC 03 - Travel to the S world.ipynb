{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\"  src=\"images/LogoP.jpg\" width=\"200\">\n",
    "\n",
    "# Linear AC 04 - Travel to the S world\n",
    "\n",
    "This document deals with **Laplace Transform**, that give an alternative to our common time domain. Using this new domain, a lot of complex operations are streamlined.\n",
    "\n",
    "Version 1.0 (26/4/2019)  \n",
    "License information is at the end of the document\n",
    "\n",
    "---\n",
    "**Bill Of Materials (BOM):**\n",
    "\n",
    "* Two capacitors of $10nF$ and $100nF$\n",
    "* Two $47k \\Omega$ Resistors\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the previous chapter we have seen that we can describe any **Linear Time- Invariant (LTI)** system by its **impulsional response** $h(t)$. We have also seen that the response of a system $y(t)$ to any input $x(t)$ can be obtained by the **convolution** of the input and the system's impulsional response.\n",
    "\n",
    "$$y(t) = x(t) * y(t)$$\n",
    "\n",
    "But the convolution is a complicated integral operator.\n",
    "\n",
    "Also obtaining the **impulsional response** of a circuit involves solving **differential equations**.\n",
    "\n",
    "We don't want to calculate convolutions.\n",
    "\n",
    "We don't want to mess with differential equations.\n",
    "\n",
    "Wouldn't be great to have a world where we don't need to care about those complex things? Well, there exists this world, but it is out of time. It is the **S Laplace** world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponentials to the rescue\n",
    "\n",
    "Exponentials are very interesting functions. Specially when the $e$ base is used. That is because they are inmune to the **derivative** and **integral** operators.\n",
    "\n",
    "$$e^t =\\frac{d}{dt} e^t = \\int e^t dt$$\n",
    "\n",
    "They are autofunctions of **LTI** systems because the output of a **LTI** system to any exponential is the same exponential just multiplied by a constant. This also worls if time $t$ is multiplied by any $s$ constant in the exponent.\n",
    "\n",
    "$$e^{a \\cdot t} \\overset{f}{\\longrightarrow} k \\cdot e^{a \\cdot t}$$\n",
    "\n",
    "Let's consider a generic exponential function f that depends on time:\n",
    "\n",
    "$$f(t)=B\\cdot e^{a\\cdot t}$$\n",
    "\n",
    "The derivative of $f(t)$ is:\n",
    "\n",
    "$$\\frac{d}{dt} f(t) = a \\cdot B \\cdot e^{a \\cdot t} = s \\cdot f(t)$$\n",
    "\n",
    "The integral of $f(t)$ is:\n",
    "\n",
    "$$\\int f(t) \\; dt = \\frac{1}{a} \\cdot B \\cdot e^{a \\cdot t} = \\frac{f(t)}{a}$$\n",
    "\n",
    "So, if we have an exponential with an $s\\cdot t$ exponent, the derivative is just the same exponential multiplied by $s$ and the derivative is the same exponential divided by $s$.\n",
    "\n",
    "If any input $x(t)$ function we can feed to an **LTI** system could be represented by a sum of exponential functions, then, the output $y(t)$ will contain just the same exponentials although each one multiplied by a different constant. Not only that, but derivatives and integrals of $x(t)$ are substituted by multiplications and divisions. All the complex work of solving **differential equations** could be converted in just normal algebra.\n",
    "\n",
    "Before continuing we will import some **Python** modules to give examples of the mathematics concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules\n",
    "\n",
    "We will need to import both the **SLab** and the **numpy** modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the main SLab module\n",
    "import slab\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Transform\n",
    "\n",
    "As said before, if we only deal with functions that are a sum of a list of **exponentials** every thing will be eased because **derivatives** and **integrals** transform into **multiplications** and **divisions**. For instance, we could describe a signal $x(t)$ as a sum of exponentials:\n",
    "\n",
    "$$x(t)=\\sum_{i=0}^n B_i e^{a_i t}$$\n",
    "\n",
    "Then, when we could operate with $x(t)$ using this summation. For instance, we can multiply it by a constant $C$.\n",
    "\n",
    "$$C \\cdot x(t)=C \\cdot \\sum_{i=0}^n B_i e^{a_i t} = \\sum_{i=0}^n C \\cdot B_i e^{a_i t}$$\n",
    "\n",
    "We can obtain the **derivative** of $x(t)$:\n",
    "\n",
    "$$\\frac{d}{dt}x(t) = \\frac{d}{dt} \\sum_{i=0}^n B_i e^{a_i t} = \\sum_{i=0}^n a_i B_i e^{a_i t} $$\n",
    "\n",
    "And we can obtain the **integral** of $x(t)$:\n",
    "\n",
    "$$\\int x(t) \\; dt = \\int \\sum_{i=0}^n B_i e^{a_i t} \\; dt = \\sum_{i=0}^n \\frac{B_i}{a_i} e^{a_i t} $$\n",
    "\n",
    "But working with **summations** is tedious. It will be more interesting to join the list of exponentials in just one function that includes all exponential elements. In this function, instead of using the time $t$ variable we will use the $s$ variable that corresponds to the exponent of an **exponential** function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Transform\n",
    "\n",
    "The **Laplace S Transform** ( $\\mathcal{L}$ ) converts a function $f(t)$ from the **time domain** to a function $F(s)$ in and **exponential Laplace domain**. The exponential domain has no time, only how to represent the signals using just exponentials. So, in the **Laplace \"s\"** domain, the variable is the **s exponent** of the exponentials that compose the function.\n",
    "\n",
    "$$x(t) \\overset{\\mathcal{L}}{\\longrightarrow} X(s)$$\n",
    "\n",
    "Each exponential in the **time domain** will have a **peak** or **\"pole\"** in the **Laplace \"s\"** domain for the $s$ value that corresponds to its exponent. For instance, let's consider the following function:\n",
    "\n",
    "$$x(t) = 2 \\cdot e^{-5\\cdot t}$$\n",
    "\n",
    "The following code cell shows it in the **time domain**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0,1,200)   # Define a time vector\n",
    "x = 2*np.exp(-5*t)         # Compute x(t)\n",
    "\n",
    "# Show x(t)\n",
    "slab.plot11(t,x,'x(t) function','time','x(t)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we are not using units here. The mathematical concepts of the **Laplace Transform** are independent on the particular units we use. So, our plots are in **arbitrary units**.\n",
    "\n",
    "Before explaining how this **Laplace Transform** is computed, it is interesting to know what is its shape. Don't worry now about the details on how the $X(s)$ function is computed. We will deal with that later. Let's advance how an exponential in the time domain transforms to its equivalent in the **Laplace \"s\"** domain.\n",
    "\n",
    "$$e^{a\\cdot t} \\overset{\\mathcal{L}}{\\longrightarrow} \\frac{1}{s-a} $$\n",
    "\n",
    "So, in our particular case:\n",
    "\n",
    "$$2 \\cdot e^{-5\\cdot t} \\overset{\\mathcal{L}}{\\longrightarrow} \\frac{2}{s+5}$$\n",
    "\n",
    "Now, we will see what is the shape of the **Laplace Transform** $X(s)$ of our $x(t)$ function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.linspace(-10,0,200) # Define a s vector\n",
    "X = 2/(s+5)                # Compute X(s)\n",
    "\n",
    "# Show X(s)\n",
    "slab.plot11(s,X,'X(s) function in \"s\" domain','s','X(s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the $X(s)$ function has an [Asymptote](https://en.wikipedia.org/wiki/Asymptote) at the $s$ values associated to the exponent of our function. At the point where $s=-5$, in our case, the function $X(s)$ goes infinite.\n",
    "\n",
    "In a similar way, if we have a function composed of two exponentials:\n",
    "\n",
    "$$x_2(t) = 2 \\cdot e^{-5\\cdot t} - 3 \\cdot e^{-8\\cdot t}$$\n",
    "\n",
    "We can obtain it in the **time domain**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t  = np.linspace(0,1,200)              # Define a time vector\n",
    "x2 = 2*np.exp(-5*t) - 3*np.exp(-8*t)   # Compute x2(t)\n",
    "\n",
    "# Show x(t)\n",
    "slab.plot11(t,x2,'$x_2(t)$ function','time','$x_2(t)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in the **Laplace** domain.\n",
    "\n",
    "$$2 \\cdot e^{-5\\cdot t} - 3 \\cdot e^{-8\\cdot t}\n",
    "\\overset{\\mathcal{L}}{\\longrightarrow} \n",
    "\\frac{2}{s+5} - \\frac{3}{s+8}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s  = np.linspace(-10,0,200) # Define a s vector\n",
    "X2 = 2/(s+5) - 3/(s+8)      # Compute X2(s)\n",
    "\n",
    "# Show X2(s)\n",
    "slab.plot11(s,X2,'$X_2(s)$ function in \"s\" domain','s','$X_2(s)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that we only have one function $X_2(s)$ but it contains information of all the exponentials contained in the original $x_2(t)$ function. No need to use **summations**.\n",
    "\n",
    "Note that, in the graph, the **peaks**, or **poles** as we will call them from now on, seem to have different height, this is a plot artifact, all peaks go to $\\pm \\infty$.\n",
    "\n",
    "We can obtain the **derivative** of $x_2(t)$ in the time domain and show it also in the **Laplace** domain. \n",
    "\n",
    "Note that we are not showing the derivative respect to $s$ in the **Laplace** domain, but the **Laplace** transform of the time derivative of the $x_2(t)$ function.\n",
    "\n",
    "$$\\frac{d}{dt} \\left( 2 \\cdot e^{-5\\cdot t} - 3 \\cdot e^{-8\\cdot t} \\right)\n",
    "= -5 \\cdot 2 \\cdot e^{-5\\cdot t} + 8 \\cdot 3 \\cdot e^{-8\\cdot t}\n",
    "\\overset{\\mathcal{L}}{\\longrightarrow} \n",
    "-\\frac{10}{s+5} + \\frac{24}{s+8}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t  = np.linspace(0,1,200)                   # Define a time vector\n",
    "dx = -5*2*np.exp(-5*t) + 3*8*np.exp(-8*t)   # Compute d x(t) / dt\n",
    "\n",
    "# Show x(t)\n",
    "slab.plot11(t,dx,'Derivative of $x_2(t)$','time','d x(t) / dt')\n",
    "\n",
    "dX2 = -5*2/(s+5) + 8*3/(s+8)      # Compute transform of the derivative of x2(t)\n",
    "\n",
    "# Show X2(s)\n",
    "slab.plot11(s,dX2,'Laplace transform of the derivative of $x_2(t)$'\n",
    "             ,'s','$\\mathcal{L}(d x(t) /dt)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is not much apparent change in the **Laplace** domain compared with the change in the time domain. This is because information about the exponentials are in the **poles** and, if a funtion goes to $\\infty$ and you multiply it with a constant, it will also go to $\\infty$ afterwards.\n",
    "\n",
    "The same derivative could be performed in the **Laplace** domain. As we known, the derivative of an exponential with exponent $s$ is just the same exponential multiplied by $s$, so, in the laplace domain:\n",
    "\n",
    "$$\\mathcal{L} \\left( \\frac{d}{dt}x_2(t) \\right) = s \\cdot X_2(s)$$\n",
    "\n",
    "Let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute dX2 in the laplace domain\n",
    "dX2B = s*X2    # Compute derivative in Laplace domain\n",
    "\n",
    "# Show both derivatives\n",
    "slab.plot1n(s,[dX2,dX2B],'Derivatives compared','s','$\\mathcal{L}(d x(t) /dt)$'\n",
    "            ,['calculated in time domain','calculated in s domain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both functions are exactly the same.\n",
    "\n",
    "As you can see, once we are in the **Laplace \"s\"** domain, the time derivatives can be computed in this domain just multiplying by $s$ the $X(s)$ function that contains all the exponentials that were in $x(t)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining a complete set of exponentials\n",
    "\n",
    "All is sound and good, but, as we explained, all this work is to convert a function $x(t)$ in a transformed function $X(s)$ in the **Laplace** domain where **derivatives** and **integrals** are much simpler. As the **Laplace** domain deals with exponentials, we need to be able to describe all $x(t)$ functions just adding exponentials like:\n",
    "\n",
    "$$f(t) = B \\cdot e^{a \\cdot t}$$\n",
    "\n",
    "The problem is that a lot of functions cannot be described with any list of exponential functions with **real** $B$ and $a$ values. \n",
    "\n",
    "But the set of exponentials can be complete if we go out of the **real** numbers. If now, we define the constants $B$ and $a$ inside the **set** of [Complex Numbers](https://en.wikipedia.org/wiki/Complex_number) then, any $x(t)$ function you can imagine, can be defined with exponentials.\n",
    "\n",
    "Complex numbers expand the **Real numbers** set by providing solutions that are out of the **Real** domain. **Real numbers** are defined in a line. **Complex numbers** are defined in a plane. So, every $z$ complex number has two components. A real component $\\sigma$ and an imaginary component $\\omega$.\n",
    "\n",
    "$$z = \\sigma + j\\cdot \\omega$$\n",
    "\n",
    "Note that the $j$ symbol represents the square root of -1 that has no solution in the **real** domain. That's why its called **imaginary**. In **electrical engineering** we use $j$ instead of $i$, as is used in **mathematics**, because we usually use $i$ for the electrical current.\n",
    "\n",
    "$$j = \\sqrt{-1}$$\n",
    "\n",
    "At this point it is interesting to see the [Euler](https://en.wikipedia.org/wiki/Euler%27s_formula) formula for exponentials of **imaginary** numbers.\n",
    "\n",
    "$$e^{j\\omega} = cos(\\omega) + j \\cdot sin(\\omega)$$\n",
    "\n",
    "The following code shows the real and imaginary components of the exponential with an imaginary exponent like in the above formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.linspace(-5,5,200)\n",
    "e = np.exp(1j*w)\n",
    "slab.plot1n(w,[np.real(e),np.imag(e)],''\n",
    "            ,'$\\omega$','exp ( j $\\omega$ )',['Real','Imaginary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Euler](https://en.wikipedia.org/wiki/Euler%27s_formula) formula is related to an alternative polar representation of the complex numbers.\n",
    "\n",
    "![Polar](images\\Linear_AC_03\\polar.png)\n",
    "\n",
    "A complex number can be represented by the **Real** $\\sigma$ and **Complex** $\\omega$ components or by a **modulus** $|z|$ and **phase** $\\varphi_z$. The **Euler** formula can be used to relate both representations.\n",
    "\n",
    "$$z = |z| e^{j\\; \\varphi_z} = |z| cos(\\varphi_z) + j \\; |z| \\; sin(\\varphi_z) \n",
    "= \\sigma + j \\omega$$\n",
    "\n",
    "$$\\sigma = |z| cos(\\varphi_z) \\qquad \\omega = |z| sin(\\varphi_z)$$\n",
    "\n",
    "$$|z| = \\sqrt{\\sigma^2 + \\omega^2} \\qquad \\varphi_z \n",
    "= arctan \\left( \\frac{\\omega}{\\sigma} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous exponential plot only shows exponentials with full **imaginary** $j \\omega$ exponent. In general, an exponential can have any $z=\\sigma +  j \\omega$ exponent.\n",
    "\n",
    "$$e^z = e^{\\sigma + j \\omega} = e^\\sigma (cos(\\omega) + j \\cdot sin(\\omega))$$\n",
    "\n",
    "The following code shows the real and imaginary components of the exponential with an arbitrary $z=\\sigma +  j \\omega$ **complex** exponent.\n",
    "\n",
    "$$e^{\\sigma + j \\omega} = e^\\sigma (cos(\\omega) + j \\cdot sin(\\omega))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential 3D function to plot\n",
    "# Functions to plot shall have only X and Y arguments\n",
    "# We will use X for the real part of Z and Y for the imaginary part\n",
    "# The function returns an imaginary value and we cannot directly plot that\n",
    "def f(x,y):\n",
    "    z = x+y*1j\n",
    "    return np.exp(z)\n",
    "\n",
    "# The plotFunc3D plots the function f in the X domain (-1,1) and Y domain(-10,10)\n",
    "# Using the postprocessing function np.real we show the real part\n",
    "# When we use the fpost parameter the function we are plotting is fpost(f(X,Y))\n",
    "slab.plotFunc3D(f,(-1,1),(-10,10),'','$\\sigma$','$\\omega$','Real exp(z)',fpost=np.real)\n",
    "\n",
    "# Using the postprocessing function np.real we show the imaginary part\n",
    "slab.plotFunc3D(f,(-1,1),(-10,10),'','$\\sigma$','$\\omega$','Imag exp(z)',fpost=np.imag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that, as the exponential function has a complex domain and an complex result, we need two 3D figures, one to show the **Real** part of result and another to show the **Imaginary** part. We could try to show both figures in the same **3D** plot but it would be a mess.\n",
    "\n",
    "Note also that the previous 2D figure of the exponential with only imaginary argument is the cross of the above 3D images with the plane with $\\sigma = 0$. Also note that an exponential with **Real** argument, that is, with $\\omega = 0$ has no imaginary component in the result, and the **Real** result is just our known **Real** exponential function.\n",
    "\n",
    "As you can see, when using a $\\sigma + i \\omega$ argument on the exponential function you get the **cosine** in the real output and the **sine** in the imaginary output both along the imaginary $\\omega$ axis. Also you get a real exponential function along the real $\\sigma$ axis.\n",
    "\n",
    "As we know by now, we have two alternatives to showing complex numbers **Real and Imaginary** and **Modulus and Phase**, so we can show the above function using now the second alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Exponential 3D function to plot\n",
    "def f(x,y):\n",
    "    z = x+y*1j\n",
    "    return np.exp(z)\n",
    "\n",
    "# Using the postprocessing function np.absolute we show the modulus\n",
    "slab.plotFunc3D(f,(-1,1),(-10,10),'','$\\sigma$','$\\omega$','modulus',fpost=np.absolute)\n",
    "\n",
    "# Using the postprocessing function np.angle we show the phase\n",
    "slab.plotFunc3D(f,(-1,1),(-10,10),'','$\\sigma$','$\\omega$','$phase$',fpost=np.angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above figures are interesting because they show how closely the exponentials relate to the polar representation as indicated by the **Euler** formula. The **modulus** is independent on imaginary $\\omega$ component and the phase is independent on the $\\sigma$ real component. Note also how the phase is [periodic](https://en.wikipedia.org/wiki/Periodic_function) and linear each $2\\pi$ interval. In fact, in our case, $\\varphi_z = \\omega$ although it warps when we go outside of the $\\pm \\pi$ interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the [Euler](https://en.wikipedia.org/wiki/Euler%27s_formula) formula we can also relate the sine and cosine functions to the exponential functions. We can start on the **Euler** formula:\n",
    "\n",
    "$$e^{i\\omega} = cos(\\omega) + j \\cdot sin(\\omega)$$\n",
    "\n",
    "Changing the sign we get:\n",
    "\n",
    "$$e^{-i\\omega} = cos(-\\omega) + j \\cdot sin(-\\omega)$$\n",
    "\n",
    "But $\\; cos(x) = cos(-x) \\;$ and $\\; sin(-x) = -sin(x) \\;$ so we get:\n",
    "\n",
    "$$e^{i\\omega} = cos(\\omega) + j \\cdot sin(\\omega)$$\n",
    "\n",
    "$$e^{-i\\omega} = cos(\\omega) - j \\cdot sin(\\omega)$$\n",
    "\n",
    "Adding both equations we can obtain:\n",
    "\n",
    "$$cos(\\omega)=\\frac{e^{j\\omega}+e^{-j\\omega}}{2}$$\n",
    "\n",
    "You can check the above function by executing the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a vector with 200 points between -5 and 5\n",
    "w = np.linspace(-5,5,200)\n",
    "# Obtain the cosine using two exponentials\n",
    "f = (np.exp(1j*w)+np.exp(-1j*w))/2.0\n",
    "# Show the cosine function (It should only have Real values)\n",
    "slab.plot1n(w,[np.real(f),np.imag(f)],'Cosine function from exponentials'\n",
    "            ,'$\\omega$'\n",
    "            ,'$(\\;exp ( i \\omega ) + exp ( -j \\omega )\\;)\\; / \\;2$'\n",
    "            ,['Real','Imaginary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember our two previous equations:\n",
    "\n",
    "$$e^{j\\omega} = cos(\\omega) + j \\cdot sin(\\omega)$$\n",
    "\n",
    "$$e^{-j\\omega} = cos(\\omega) - j \\cdot sin(\\omega)$$\n",
    "\n",
    "Substracting them we get:\n",
    "\n",
    "$$sin(\\omega)=\\frac{e^{j\\omega}-e^{-j\\omega}}{2 j}$$\n",
    "\n",
    "You can also check the above function by executing the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a vector with 200 points between -5 and 5\n",
    "w = np.linspace(-5,5,200)\n",
    "# Obtain the sine using two exponentials\n",
    "f = (np.exp(1j*w)-np.exp(-1j*w))/2j\n",
    "# Show the sine function (It should only have Real values)\n",
    "slab.plot1n(w,[np.real(f),np.imag(f)],'Sine function from exponentials'\n",
    "            ,'$\\omega$'\n",
    "            ,'$(\\;exp ( i \\omega ) - exp ( -j \\omega )\\;)\\; / \\;2j$'\n",
    "            ,['Real','Imaginary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Transform Revisited\n",
    "\n",
    "Now we have a broader domain for our **Laplace Transform** we won't define $s$ in a **Real** line but in a **Complex** plane. Our previous function:\n",
    "\n",
    "$$x_2(t) = 2 \\cdot e^{-5\\cdot t} - 3 \\cdot e^{-8\\cdot t}$$\n",
    "\n",
    "Was previously shown, using only **Real** $s$ values as in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s  = np.linspace(-10,0,200) # Define a s vector\n",
    "X2 = 2/(s+5) - 3/(s+8)      # Compute X2(s)\n",
    "\n",
    "# Show X2(s)\n",
    "slab.plot11(s,X2,'$X_2(s)$ function in \"s\" domain','s','$X_2(s)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can show this function in its full glory in the **complex \"S\"** plane. As the function have **asymptotes** that go to **infinity**, we will **clip** the function at $\\pm 10$ both in the **real** and **imaginary** result to ease the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 3D function to plot\n",
    "def f(x,y):\n",
    "    z = x+y*1j\n",
    "    return 2/(z+5) - 3/(z+8)\n",
    "\n",
    "# Use np.real to show the real part\n",
    "# The clip parameter defines the limits (minZ,maxZ) of the values in the Z axis\n",
    "slab.plotFunc3D(f,(-10,0),(-5,5),'','$\\sigma$','$\\omega$','Real'\n",
    "                 ,clip=(-10,10),fpost=np.real)\n",
    "\n",
    "# Use np.imag to show the imaginary part\n",
    "slab.plotFunc3D(f,(-10,0),(-5,5),'','$\\sigma$','$\\omega$','Imag'\n",
    "                 ,clip=(-10,10),fpost=np.imag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can represent again this function using **Modulus and Phase** instead of showing the **Real and Imaginary** components by using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D function to plot\n",
    "def f(x,y):\n",
    "    z = x+y*1j\n",
    "    return 2/(z+5) - 3/(z+8)\n",
    "\n",
    "# Modulus\n",
    "slab.plotFunc3D(f,(-10,0),(-5,5),'','$\\sigma$','$\\omega$','Modulus'\n",
    "                 ,clip=(-10,10),fpost=np.absolute)\n",
    "\n",
    "# Phase\n",
    "slab.plotFunc3D(f,(-10,0),(-5,5),'','$\\sigma$','$\\omega$','Phase'\n",
    "                 ,fpost=np.angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the **modulus** clearly shows the two **poles** that correspond to the two exponentials in the $x_2(t)$ function. The **phase** however, is quite strange. One part of the problems when plotting the **phase** is that it wraps when it goes outside the $\\pm \\pi$ range. So, it could seen discontinuous when it is not. It just wraps.\n",
    "\n",
    "To prevents problems with phase wrapping we can use the **unwrap** function of the **numpy** module to show a more continuous phase as we can see in the code below. Note that in a 3D plot it is not always possible to prevent all phase wrappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newAngle postprocessing function that unwraps the obtained angle\n",
    "def newAngle(a):\n",
    "    return np.unwrap(np.angle(a))\n",
    "\n",
    "# New Phase Plot\n",
    "slab.plotFunc3D(f,(-10,0),(-5,5),'','$\\sigma$','$\\omega$','Phase'\n",
    "                 ,fpost=newAngle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, we will use this new **unwrapped** phase.\n",
    "\n",
    "As another example of function in the **s plane**, let's recall that we have seen that the **sine** function can be computed with exponentials:\n",
    "\n",
    "$$sin(\\omega \\cdot t)=\\frac{e^{j\\omega \\cdot t}-e^{-j\\omega \\cdot t}}{2 j} \n",
    "= \\frac{e^{j\\omega \\cdot t}}{2 j} - \\frac{e^{-j\\omega \\cdot t}}{2 j}$$\n",
    "\n",
    "Then, in the **Laplace** domain we will have:\n",
    "\n",
    "$$\\mathcal{L}(\\: sin(\\omega \\cdot t)\\; u(t) \\:) \n",
    "= \\frac{1}{2j} \\left( \\frac{1}{s-j\\omega} - \\frac{1}{s+j\\omega} \\right)\n",
    "= \\frac{\\omega}{s^2+\\omega^2}$$\n",
    "\n",
    "We can see this function also in the **Laplace** domain. In this case for the particular case of $\\omega = 5$. We will clip the values at $\\pm 1$ so that we see more detail on the low values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D function to plot\n",
    "def f(x,y):\n",
    "    z = x+y*1j\n",
    "    return 5/(z*z+25)\n",
    "\n",
    "# Real\n",
    "slab.plotFunc3D(f,(-10,10),(-10,10),'','$\\sigma$','$\\omega$','Real'\n",
    "                 ,clip=(-1,1),fpost=np.real)\n",
    "\n",
    "# Imaginary\n",
    "slab.plotFunc3D(f,(-10,10),(-10,10),'','$\\sigma$','$\\omega$','Imag'\n",
    "                 ,clip=(-1,1),fpost=np.imag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we can show the same functions in **Modulus** and unwrapped **Phase**. We will clip the **modulus** at $1.0$ so that we see more detail in the low values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D function to plot\n",
    "def f(x,y):\n",
    "    z = x+y*1j\n",
    "    return 5/(z*z+25)\n",
    "\n",
    "# Modulus\n",
    "slab.plotFunc3D(f,(-10,10),(-10,10),'','$\\sigma$','$\\omega$','Modulus'\n",
    "                 ,clip=(-1,1),fpost=np.absolute)\n",
    "\n",
    "# Phase\n",
    "slab.plotFunc3D(f,(-10,10),(-10,10),'','$\\sigma$','$\\omega$','Phase'\n",
    "                 ,fpost=newAngle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And **again**, we see the two **poles** that correspond to the two exponentials in the **sine** function and **again**, the phase, although unwrapped, is quite strange. \n",
    "\n",
    "At this point you can see that showing the **Real** and **Imaginary** components of the functions shows similar although not equal plots. Of all the plots, the **modulus** one is the pretier. This is partly because, asymptotes that go to $+\\infty$ and then return from $-\\infty$, in **modulus** only go to $+\\infty$. We see, also, that the **phase**, in general, gives low intuitive information about what is happening in the function. From all the previous discussion, it is habitual to show only the **Modulus** plot. It is the prettiest and it is the most intuitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Transform Details\n",
    "\n",
    "In the previous sections we have explained some of the **Laplace Transform** ($\\mathcal{L}$) properties and we have advanced the transform of an exponential function:\n",
    "\n",
    "$$e^{a\\cdot t} \\overset{\\mathcal{L}}{\\longrightarrow} \\frac{1}{s-a} $$\n",
    "\n",
    "In a coloquial term, the **Laplace Transform** computes how much there is of an exponential $e^{s\\cdot t}$ at each $s$ point in the complex plane. If our function $x(t)$ contains any $e^{z\\cdot t}$ exponential, we will get a **pole** when $s$ equals $z$ in $X(s)$. \n",
    "\n",
    "$$x(t) \\overset{\\mathcal{L}}{\\longrightarrow} X(s)$$\n",
    "\n",
    "It is now time to get into the details. There are, in fact, two [Laplace Transforms](https://en.wikipedia.org/wiki/Laplace_transform), the **unilateral** and the **bilateral** ones.\n",
    "\n",
    "In electronics we typically use the **unilateral** Laplace transform. This transform only deals with functions that are zero for negative time values.\n",
    "\n",
    "$$X(s) = \\int_0^\\infty x(t) e^{-st} dt$$\n",
    "\n",
    "As you remember, the **Unity Step Function** $u(t)$ has a zero value for negative times and a one value for positive times, so, as the transform requires zero negative time values, we usually multiply our time domain function by the **step function** before the **Laplace** transformation to the $S$ domain.\n",
    "\n",
    "$$x(t) \\; u(t) \\overset{\\mathcal{L}}{\\longrightarrow} X(s) $$\n",
    "\n",
    "So, the correct transform associated to the exponential is:\n",
    "\n",
    "$$e^{a\\cdot t} u(t) \\overset{\\mathcal{L}}{\\longrightarrow} \\frac{1}{s-a} $$\n",
    "\n",
    "As indicated previously, the **Laplace** transform is computed for each possible **complex s value**. So, the **\"s\" domain** is a complex plane whereas the **time domain** is a real line. This is important because we can fit much more information in a plane than in a line. So, every $x(t)$ function has a **Laplace Transform** but not every possible $X(s)$ function corresponds to a **Real** $x(t)$ function.\n",
    "\n",
    "The **Laplace** transform definition makes easy to operate on sums:\n",
    "\n",
    "$$\\int_0^\\infty \\left( x_1(t)+x_2(t) \\right) e^{-st} dt \n",
    "= \\int_0^\\infty x_1(t) e^{-st} dt + \\int_0^\\infty x_2(t) e^{-st} dt \n",
    "= X_1(s) + X_2(s)$$\n",
    "\n",
    "$$x_1(t) + x_1(t) \\overset{\\mathcal{L}}{\\longrightarrow} X_1(s) + X_2(s)$$\n",
    "\n",
    "Same applies for constant multiplications:\n",
    "\n",
    "$$\\int_0^\\infty k \\cdot x(t) e^{-st} dt \n",
    "= k \\int_0^\\infty x(t) e^{-st} dt \n",
    "= k \\cdot X(s) + X$$\n",
    "\n",
    "$$k \\: x(t) \\overset{\\mathcal{L}}{\\longrightarrow} k \\: X(s)$$\n",
    "\n",
    "Remember that the the time derivative converts to a $s$ multiplication in the **s plane**. In the case of the **unilateral** transform, however, we need to add a term that depends on the function at zero time:\n",
    "\n",
    "$$\\frac{d}{dt} x(t) \\overset{\\mathcal{L}}{\\longrightarrow} s \\: X(s) - x(t=0)$$\n",
    "\n",
    "The time integral is, just as we found before, equivalent to a $s$ division:\n",
    "\n",
    "$$\\int_0^t x(\\tau) d\\tau \\overset{\\mathcal{L}}{\\longrightarrow} \\frac{X(s)}{s}$$\n",
    "\n",
    "We can also add some transforms of typical functions. In the case of the **sine** and **cosine** as explained before, they can be obtained from the exponential functions.\n",
    "\n",
    "$\\qquad u(t) \\overset{\\mathcal{L}}{\\longrightarrow} \\frac{1}{s}$\n",
    "\n",
    "$\\qquad e^{at} u(t) \\overset{\\mathcal{L}}{\\longrightarrow} \\frac{1}{s-a} \\qquad $ Note that when $a=0$ we get the transform of $u(t)$\n",
    "\n",
    "$\\qquad sin(\\omega \\: t)\\: u(t) \\overset{\\mathcal{L}}{\\longrightarrow} \n",
    "\\frac{\\omega}{s^2+\\omega^2} \\qquad$ We have deduced that before\n",
    "\n",
    "$\\qquad cos(\\omega \\: t)\\: u(t) \\overset{\\mathcal{L}}{\\longrightarrow} \n",
    "\\frac{s}{s^2+\\omega^2} \\qquad$ We can obtain that using the derivative of the sine\n",
    "\n",
    "$\\qquad \\delta(t) \\overset{\\mathcal{L}}{\\longrightarrow} 1 \\qquad$ This is the [Dyrac Delta](https://en.wikipedia.org/wiki/Dirac_delta_function) $\\delta(t)$\n",
    "\n",
    "The **Dyrac Delta** transform can be deduced from the fact that:\n",
    "\n",
    "$$\\delta(t) = \\frac{d}{dt}u(t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impulsional Response and Transfer function\n",
    "\n",
    "We know that the **Impulsional Response** $h(t)$ is the system's response to the **Dirac Delta** function $\\delta(t)$. In the **s domain**, the $H(s)$ function is the response to the **unity** $1$ function. So, for a circuit with input $x(t)$ and output $y(t)$, in the **time domain** and input $X(s)$ and output $Y(s)$ in the **s domain**, the $H(s)$ function can be calculated:\n",
    "\n",
    "$$H(s) = \\frac{Y(s)}{X(s)}$$\n",
    "\n",
    "This $H(s)$ function is called the [Transfer Function](https://en.wikipedia.org/wiki/Transfer_function) of our **LTI** system.\n",
    "\n",
    "As we know, the **Laplace transform** eases the solving of differential equations because the derivative is converted in just a $s$ multiplication. We will show now, how to apply this method to solve a circuit.\n",
    "\n",
    "In order to solve a circuit's $h(t)$ response we could obtain its equations, transform them to the **s domain**. Then we can solve them in this domain, where differential equations are easier to solve, so we obtain the $H(s)$ **Transfer function**. Finally we can transform $H(s)$ to the time domain to obtain $h(t)$.\n",
    "\n",
    "As an example, remember the **RC circuit** we have dealt with in previous tutorials:\n",
    "\n",
    "![Circuit](images\\Linear_AC_03\\circuit2.png)\n",
    "\n",
    "Its equations are:\n",
    "\n",
    "$$i_c(t) = \\frac{1}{R} ( v_{DAC1}(t) - v_c(t) )$$\n",
    "\n",
    "$$i_c(t) = C \\frac{d}{dt} v_c(t)$$\n",
    "\n",
    "That gives:\n",
    "\n",
    "$$ C \\frac{d}{dt} v_c(t) = \\frac{1}{R} ( v_{DAC1}(t) - v_c(t) )$$\n",
    "\n",
    "If we use the **Laplace** transform we get:\n",
    "\n",
    "$$C \\cdot s \\cdot (V_c(s)-v_c(t=0)) = \\frac{1}{R} ( V_{DAC1}(s) - V_c(s) )$$\n",
    "\n",
    "If we have no initial conditions $V_c(t=0) =0$ then:\n",
    "\n",
    "$$C \\cdot s \\cdot V_c(s) = \\frac{1}{R} ( V_{DAC1}(s) - V_c(s) )$$\n",
    "\n",
    "So, aplying some algebra:\n",
    "\n",
    "$$V_c(s) \\; (1+ RCs) = V_{DAC1}(s)$$\n",
    "\n",
    "If we define the input at $v_{DAC1}$ and the output at $v_c$, we get:\n",
    "\n",
    "$$H(s) = \\frac{V_c(s)}{V_{DAC1}(s)}=\\frac{1}{1+RCs}=\\frac{1}{RC} \\frac{1}{\\frac{1}{RC}+s}$$\n",
    "\n",
    "Like in other cases, as the $R \\cdot C$ product has time units we redefine it as the **time constant** $\\tau$\n",
    "\n",
    "$$H(s) = \\frac{1}{\\tau} \\frac{1}{\\frac{1}{\\tau}+s} \\qquad \\tau = R \\cdot C$$\n",
    "\n",
    "Now, we can obtain $h(t)$ from $H(s)$. As we remember, the transform of an exponential function is:\n",
    "\n",
    "$$e^{at}u(t) \\overset{\\mathcal{L}}{\\longrightarrow} \\frac{1}{s-a}$$\n",
    "\n",
    "So, by identification we get:\n",
    "\n",
    "$$h(t)=\\frac{1}{\\tau} e^{-\\frac{t}{\\tau}}$$\n",
    "\n",
    "This is, as we know from other tutorials, the **impulsional response** of our circuit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response to input\n",
    "\n",
    "We could use the **impulsional response** $h(t)$ and apply convolution to obtain the response $v_c(t)$ of the circuit against any $v_x(t)$ input. But, as we have the impulsional response $H(s)$ in the **s domain**, we can use:\n",
    "\n",
    "$$V_c(s) = H(s) \\; V_{DAC1}(s)$$\n",
    "\n",
    "That's why $H(s)$ is called the **Transfer function**, because it directly relates the input and the output when we are working in the **s domain**. Its equivalent in the **time domain**, the **Impulse response** requieres a **convolution** to relate input and output.\n",
    "\n",
    "For instance, if $v_{DAC1}(t)$ is the **unity step** function $u(t)$, we can calculate:\n",
    "\n",
    "$$V_c(s) = H(s) \\; U(s)= \\frac{1}{\\tau} \\frac{1}{\\frac{1}{\\tau}+s} \\frac{1}{s}$$\n",
    "\n",
    "After some manipulation we get:\n",
    "\n",
    "$$V_c(s) = \\frac{1}{s} - \\frac{1}{\\frac{1}{\\tau}+s}$$\n",
    "\n",
    "So we can return to the time domain by identifying the exponential function:\n",
    "\n",
    "$$v_c(t) = u(t)-e^{-\\frac{t}{\\tau}}u(t) = (1-e^{-\\frac{t}{\\tau}}) \\; u(t)$$\n",
    "\n",
    "This is, the same expression for the **step response** we have obtained in previous tutorials. Check them now if you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components in the s world\n",
    "\n",
    "In our calculations we have obtained the circuit equations in the **time domain**. Then we have gone to the **s domain** to solve the equations and we have returned to the **time domain**.\n",
    "\n",
    "As you should know by now, the circuit equations are obtained by mixing the **Kirchoff's Laws** equations with the component equations.\n",
    "\n",
    "**Kirchoff's Laws** equations are just additions of voltages or currents, so they are insensitive to the **Laplace** transform. That means that they are the same  in both **time** and $s$ domains.\n",
    "\n",
    "Component equations can be defined both in $t$ and in $s$ domains. In the case of a resistor, the equations are the same:\n",
    "\n",
    "$$v_R(t)=R \\cdot i_R(t) \\qquad V_R(s)=R \\cdot I_R(s)$$\n",
    "\n",
    "In the case of the **capacitor** and **inductor** we will apply the fact that the derivative in the **time domain** converts to a $s$ multiplication in the **s domain**.\n",
    "\n",
    "$$i_C(t)=C\\frac{d}{dt}v_C(t) \\qquad I_C(s)=C ( s \\cdot V_C(s) - v_C(t=0))$$\n",
    "\n",
    "$$v_L(t)=L\\frac{d}{dt}i_L(t) \\qquad V_L(s)=L ( s \\cdot I_L(s) - i_L(t=0))$$\n",
    "\n",
    "In the case of having no initial conditions it simplifies to:\n",
    "\n",
    "$$I_C(s)=C \\; s \\; V_C(s)$$\n",
    "\n",
    "$$V_L(s)=L \\; s \\; I_L(s)$$\n",
    "\n",
    "Note that all component equations relate $I(s)$ to $V(s)$. It is usefull at this point to define for any component $X$ an **impedance** $Z_X$in the **s domain** that relates **voltage** and current:\n",
    "\n",
    "$$Z_X(s)=\\frac{V_X(s)}{I_X(s)}$$\n",
    "\n",
    "That way we can define the **s impedance** of the **resistor**, **capacitor** and inductor.\n",
    "\n",
    "![RCL](images\\Linear_AC_03\\RCL.png)\n",
    "\n",
    "If we always define the current entering in the positive node of the voltage, we get:\n",
    "\n",
    "$$Z_R(s) = \\frac{V_R}{I_R}=R\n",
    "\\qquad Z_C(s) = \\frac{V_C}{I_C} = \\frac{1}{C \\: s}\n",
    "\\qquad Z_L(s) = \\frac{V_L}{I_L} = L \\: s$$\n",
    "\n",
    "Using the **s impedances** our **RC circuit** can be described as:\n",
    "\n",
    "![zcircuit](images\\Linear_AC_03\\zcircuit.png)\n",
    "\n",
    "Now we can solve the circuit directly in the **s domain**. For simplicity we will leave the explicit $(s)$ dependence out of the voltage and current variables. Also, for simplicity, we will assume zero initial conditions.\n",
    "\n",
    "$$I_C = \\frac{V_X}{R+\\frac{1}{Cs}}$$\n",
    "\n",
    "$$V_C = \\frac{1}{Cs}I_C = \\frac{V_X}{RCs+1}$$\n",
    "\n",
    "$$H(s)=\\frac{V_C}{V_X}=\\frac{1}{RCs+1}=\\frac{1}{RC} \\frac{1}{\\frac{1}{RC}+s}$$\n",
    "\n",
    "This is the same expression obtained before.\n",
    "\n",
    "As we can see, in order to obtain the $H(s)$ for a circuit we don't need to use the **time domain** at all.\n",
    "\n",
    "Let's put that into practice in a more complex circuit, but before that, we need to connect with the board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "![Practical Icon](images/pt.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLab Setup\n",
    "\n",
    "First we connect with the board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boardFolder = ''                                # Board folder (leave '' if you use only one board)\n",
    "slab.setFilePrefix('../Files/')                 # Set File Prefix\n",
    "slab.setCalPrefix('Calibrations/'+boardFolder)  # Set Calibration Prefix         \n",
    "slab.connect()                                  # Connect to the board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always a good idea to check the board operation.\n",
    "The following cell checks the calibration for the DAC channels and the first four ADC channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check the calibration\n",
    "slab.checkCalibration(pause=False,na=4,nm=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example circuit\n",
    "\n",
    "To test our new tools we will obtain the **step response** of a circuit more complex than the one considered before.\n",
    "\n",
    "![circuit 3](images\\Linear_AC_03\\circuit3.png)\n",
    "\n",
    "In order to solve it in the **s domain** we can substitute all components, except sources, by their **s impedances**. Also we will redraw the circuit so it is simpler to analyze.\n",
    "\n",
    "![Impedances](images\\Linear_AC_03\\circuit3z.png)\n",
    "\n",
    "Now we can solve the circuit to obtain $H(s)$ **Transfer function** using the **Kirchoff's Laws** and the **impedances**.   \n",
    "We just need to build two **KCL** equations in the two closed loops of the circuit using the currents in both capacitors $I_{C1}$ and $I_{C2}$ to obtain the voltages on all impedances.\n",
    "\n",
    "---\n",
    "\n",
    "**Calculation task**  \n",
    "Solve the above circuit to obtain the $H(s)$ function\n",
    "\n",
    "$\\qquad H(s)=\\frac{V_{out}(s)}{V_{in}{s}}$\n",
    "\n",
    "---\n",
    "\n",
    "Don't continue until you are able to obtain by yourself the following result.\n",
    "\n",
    "$$H(s)=\\frac{R_1 \\; C_1 \\; s}\n",
    "{1+s(R_2 \\; C_1 + (R_1+R_2)C_2) + C_1 \\; C_2 \\; R_1 \\; R_2 \\; s^2}$$\n",
    "\n",
    "The **Transfer function** $H(s)$ is the quotient of two [polynomials](https://en.wikipedia.org/wiki/Polynomial) in the $s$ variable. This will be the case in every **LTI** system.\n",
    "\n",
    "We can show the **modulous** of the $H(s)$ function of our circuit in the **s plane**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Component values in Ohm and Farads\n",
    "R1 = 47000  \n",
    "R2 = 47000\n",
    "C1 = 100E-9\n",
    "C2 = 10E-9\n",
    "\n",
    "# 3D function to plot\n",
    "def f(x,y):\n",
    "    z = x+y*1j\n",
    "    return R1*C1*z/(1+z*(R2*C1+(R1+R2)*C2)+C1*C2*R1*R2*z*z)\n",
    "\n",
    "# Modulus (clipped at 10)\n",
    "slab.plotFunc3D(f,(-3000,0),(-1500,1500),'','$\\sigma$','$\\omega$','H(s) Modulus'\n",
    "                 ,clip=(-10,10),fpost=np.absolute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poles and Zeros\n",
    "\n",
    "We can see that we have two **negative real poles**, both with $\\omega = 0$, one closer to zero than $\\sigma = -500$ and another on the range of $sigma = -2500$. The $s$ in the numerator also provides, as you can see, a **zero** for the function when $\\sigma = \\omega = 0$\n",
    "\n",
    "If you want to see this **zero** we can zoom in the region close to the $s=0$ position as it is not as aparent as the poles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modulus (clipped at 4)\n",
    "slab.plotFunc3D(f,(-300,100),(-200,200),'','$\\sigma$','$\\omega$','H(s) Modulus'\n",
    "                 ,clip=(-4,4),fpost=np.absolute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **zero** associated to the $s$ in the $H(s)$ numerator makes $H(0)=0$. So, it nulifies any $e^{0 \\cdot t}$ exponential input. It is interesting because this exponential corresponds to a constant function. So, our circuit will get a **zero** output for any constant input. \n",
    "\n",
    "So, as we see on the plots, our transfer function has two **poles** and one **zero**.\n",
    "\n",
    "$$H(s)=\\frac{R_1 \\; C_1 \\; s}\n",
    "{1+s(R_2 \\; C_1 + (R_1+R_2)C_2) + C_1 \\; C_2 \\; R_1 \\; R_2 \\; s^2}$$\n",
    "\n",
    "Before trying to locate the poles and zeros it is a good idea to rework our **Transfer function** by dividing both numerator and denominator by the constant that multiplies $s^2$ in the denominator:\n",
    "\n",
    "$$H(s)=\\frac{ \\frac{s}{R_2 \\; C_2} }\n",
    "{\\frac{1}{C_1 \\; C_2 \\; R_1 \\; R_2 } \n",
    "+ s \\frac{R_2 \\; C_1 + (R_1+R_2)C_2}{C_1 \\; C_2 \\; R_1 \\; R_2} \n",
    "+ s^2}$$\n",
    "\n",
    "It could seem that we are complicating the formula, but that way the numbers we will get will be all above one, also we leave a naked $s^2$ term on the denominator that will come handy later.\n",
    "\n",
    "At this point everything is much easier if we substitute the components by their values:\n",
    "\n",
    "$$R_1 = R_2 = 47k\\Omega \\quad C_1 = 100nF \\quad C_2 = 10nF$$\n",
    "\n",
    "To get:\n",
    "\n",
    "$$H(s) = \\frac{k_1 \\; s}{k_2 + k_3 \\; s + s^2}$$\n",
    "\n",
    "As we have **Python**, let the machine calculate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Component values in Ohm and Farads\n",
    "R1 = 47000  \n",
    "R2 = 47000\n",
    "C1 = 100E-9\n",
    "C2 = 10E-9\n",
    "\n",
    "# Constant calculations\n",
    "k1 = 1/(R2*C2)\n",
    "k2 = 1/(C1*C2*R1*R2)\n",
    "k3 = (R2*C1+(R1+R2)*C2)/(C1*C2*R1*R2)\n",
    "\n",
    "print('k1 =',k1)\n",
    "print('k2 =',k2)\n",
    "print('k3 =',k3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to locate the **zeros** and **poles** of our transfer function $H(s)$. The **zeros** are the [roots](https://en.wikipedia.org/wiki/Zero_of_a_function) of the numerator of $H(s)$, that is, the $s$ values that make zero the numerator:\n",
    "\n",
    "$$k_1 \\; s = 0  \\quad \\rightarrow \\quad  s=0$$\n",
    "\n",
    "The only **zero** is, as we expected, just at the origin of the **s plane**.\n",
    "\n",
    "The **poles** are the **roots** of the denominator and, in our case, they are more dificult to locate as there are two of them and they are not at the origin of the **s plane**:\n",
    "\n",
    "$$k_2 + k_3 \\; s + s^2 = 0$$\n",
    "\n",
    "But we can [factorize](https://en.wikipedia.org/wiki/Factorization) the denominator to find its roots $r_1$ and $r_2$ \n",
    "\n",
    "$$r_1 = \\frac{-k_3 + \\sqrt{k_3^2-4k_2}}{2} \\qquad r_2 = \\frac{-k_3 - \\sqrt{k_3^2-4k_2}}{2}$$\n",
    "\n",
    "We can use the following code cell to obtain the position of those **poles**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = (-k3+np.sqrt(k3*k3-4*k2))/2\n",
    "r2 = (-k3-np.sqrt(k3*k3-4*k2))/2\n",
    "print('r1 =',r1)\n",
    "print('r2 =',r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare those position with the previous **s plane** graphs to see if the poles are in the locations we have calculated.\n",
    "\n",
    "So, our **Transfer function** is now:\n",
    "\n",
    "$$H(s) = \\frac{k_1 \\; s}{(s-r_1)(s-r_2)}$$\n",
    "\n",
    "It is clear in this representation that we have a **zero** at $s=0$ and two **real poles**, one at $s=r_1$ and another at $s=r_2$. We call those poles **real** because they have no imaginary components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response to a 2V step input\n",
    "\n",
    "Now, we want to get the response to a $2V$ step. We can use the $H(s)$ function for that:\n",
    "\n",
    "$$V_o(s)=H(s)\\cdot 2 U(s)=H(s) \\frac{2}{s}$$\n",
    "\n",
    "That gives:\n",
    "\n",
    "$$V_o(s) = \\frac{k_1 \\; s}{(s-r_1)(s-r_2)} \\frac{2}{s} \n",
    "=\\frac{2 \\; k_1}{(s-r_1)(s-r_2)}$$\n",
    "\n",
    "It is interesting to observe that we have the same **poles** we had before in $H(s)$, the **zero** however, is mising.\n",
    "\n",
    "To obtain $v_o(t)$ we need to return to the **time domain**. In order to do that, we can separate the two poles.\n",
    "\n",
    "$$V_o(s) = \\frac{2 \\; k_1}{(s-r_1)(s-r_2)}\n",
    "= \\frac{k_{1a}}{s-r_1} + \\frac{k_{1b}}{s-r_2}$$\n",
    "\n",
    "We can obtain $k_{1a}$ and $k_{1b}$ by solving:\n",
    "\n",
    "$$2 \\;k_1 = k_{1a}(s-r_2) + k_{1b}(s-r1)$$\n",
    "\n",
    "In more detail:\n",
    "\n",
    "$$k_{1a}+k{1_b}=0 \\quad \\rightarrow \\quad k_{1b} = -k_{1a}$$\n",
    "\n",
    "$$2 \\; k_1 = -r_2 \\: k_{1a} -r_1 \\: k_{1b}$$\n",
    "\n",
    "$$2 \\; k_1 = -r_2 \\: k_{1a} +r_1 \\: k_{1a} = k_{1a}(r_1-r_2)$$\n",
    "\n",
    "$$k_{1a} = \\frac{2 \\;k_1}{2(r_1-r_2)}$$\n",
    "\n",
    "You can use the following code cell to obtain $k_{1a}$ and $k_{1b}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1a = 2*k1/(r1-r2)\n",
    "k1b = -k1a\n",
    "print('k1a =',k1a)\n",
    "print('k1b =',k1b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, finally, in the **s domain** we get:\n",
    "\n",
    "$$V_o(s) = \\frac{1.96}{s+192} - \\frac{1.96}{s+2361}$$\n",
    "\n",
    "It is usual not to use units in the coefficients of the **s domain** polynomials although, in our case, $v_o(t)$ has **Volt** units.\n",
    "\n",
    "Going to the **time domain** by identification of the exponential functions we get:\n",
    "\n",
    "$$v_o(t)=1.96 \\; ( e^{-192 \\; t} - e^{-2361 \\; t})$$\n",
    "\n",
    "Now we can recover the units so, the correct expression is:\n",
    "\n",
    "$$v_o(t)=1.96 V \\; ( e^{-192 s^-1 \\; t} - e^{-2361 s^-1 \\; t})$$\n",
    "\n",
    "We usually use **Time constants** for the exponentials so:\n",
    "\n",
    "$$\\tau_1 = \\frac{1}{192 s^-1} = 5.2ms \n",
    "\\qquad \\tau_2 = \\frac{1}{2361 s^-1} = 423 \\mu s$$\n",
    "\n",
    "$$v_o(t)=1.96 V \\; \\left( e^\\frac{t}{5.2ms} - e^\\frac{t}{423 \\mu s} \\right)$$\n",
    "\n",
    "The following code cell shows the **step response** we have calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time vector\n",
    "t = np.linspace(0,0.05,200)                 \n",
    "# Calculate the obtained circuit response\n",
    "vo = 1.96*(np.exp(-192*t)-np.exp(-2361*t))\n",
    "# Plot it\n",
    "slab.plot11(t,vo,'Circuit response to 2V step','time [s]','Vo [V]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to compare theory and practice. **Mount** the proposed circuit and execute the following code cell to measure its 2V step response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slab.setSampleTime(0.00005)           # Set sample time to 50us\n",
    "slab.setTransientStorage(1000,2)      # Set storage for 100 samples of ADC1 and ADC2\n",
    "\n",
    "# Perform the step plot with a change of DAC1 from 0V to 2V \n",
    "# By default, DAC1 will be at the start voltage for 1s before the change\n",
    "data = slab.stepPlot(0.0,2.0,returnData=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After obtaining the step response we can compare it with our calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slab.plotnn([t,data[0]],[vo,data[2]],'Step comparison'\n",
    "            ,'time [s]','Vo [V]',['Calculation','Measurement'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the measurement match the calculations?\n",
    "\n",
    "Perhaps the match is not perfect but you need to take into account that the SLab system is not good to work near zero volts and the fact that both the capacitors and the resistances have tolerances and their real values are not exactly the same as their marked ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Last words\n",
    "\n",
    "This was a mainly theoretical document. But it is important because it sets the foundations of the frequency response. We have seen that we can work in the **s domain** if we trade **time** for **exponentials**.\n",
    "\n",
    "The **impulsional response** $h(t)$ in the **s domain** turns into the **Transfer function** $H(s)$ and can be obtained by solving the circuit using the $Z(s)$ **impedances** for its linear components. That way we don't need to start in the time domain. All the calculations to obtain $H(s)$ are performed in the **s domain**.\n",
    "\n",
    "On every **LTI** system, $H(s)$ is a **polynomial** quotient in $s$. The **roots** of the numerator are the **zeros** of $H(s)$ where it is zero, and the **roots** of the denominator are the **poles** where it has an **asymptote** that goes to infinity.\n",
    "\n",
    "Once $H(s)$ is obtained we can calculate the response of the circuit $Y(s)$ just multiplying $H(s)$ and the input $X(s)$. No **convolution** is needed.\n",
    "\n",
    "After having the circuit response $Y(s)$ the problem is usually returning to the **time domain** to obtain $y(t)$. Returning to the **time domain**, in general, is a a good idea because we live in the **time domain**. \n",
    "\n",
    "In some circuits, however, their behavior is not easy to understand in our **time domain**. In fact, they are easier to understand in the **s domain**. Those are the **frequency sensitive** circuits.\n",
    "\n",
    "We will deal with them in the next tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document license\n",
    "\n",
    "Copyright  ©  Vicente Jiménez (2019)  \n",
    "This work is licensed under a Creative Common Attribution-ShareAlike 4.0 International license.  \n",
    "This license is available at http://creativecommons.org/licenses/by-sa/4.0/\n",
    "\n",
    "<img  src=\"images/cc_sa.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
